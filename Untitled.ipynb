{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_the_files():\n",
    "    \n",
    "    \"\"\"reading the input files for the project\"\"\"\n",
    "    # reading the input file\n",
    "    data = pd.read_csv(r\"C:\\Users\\Chandu Jagarlamundi\\Desktop\\Thesis_Wind data\\Data Wind_extern\\data_eng.csv\")\n",
    "    # reading the anlagestatus file, to get the details regarding anlage status\n",
    "    status_data = pd.read_excel(r\"C:\\Users\\Chandu Jagarlamundi\\Desktop\\Thesis_Wind data\\Data Wind_extern\\system_status.xlsx\")      \n",
    "    return data, status_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = reading_the_files()\n",
    "data = files[0]\n",
    "status_data = files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):    \n",
    "    # deleting the columns which have lots of missing values\n",
    "    columns_data = data.columns\n",
    "    for i in columns_data:\n",
    "        if data[i].isna().sum()>(len(data)/2):\n",
    "            print(\"The number of missing values in the column {} are {} \".format(i,data[i].isna().sum()))\n",
    "            data.drop([i], axis = 1, inplace = True)\n",
    "    columns_data = data.columns\n",
    "    \n",
    "    # deleting the columns which have single values\n",
    "    for i in columns_data:\n",
    "        if len(data[i].value_counts())<2:\n",
    "            print(\"{} is eliminated\".format(i))\n",
    "            data.drop([i], axis = 1, inplace = True)\n",
    "            \n",
    "    data.Equipment = data.Equipment[data.Equipment!='Anlage']\n",
    "    \n",
    "    # dropping the missing rows\n",
    "    data.dropna(axis = 0, inplace=True)\n",
    "    data.drop(['Date(Remote)', 'Time(Remote)', 'Date(Server)', 'Time(Server)', \"operating_state\"], axis=1, inplace=True)\n",
    "    data.Equipment = pd.Categorical(data.Equipment, categories=data.Equipment.unique()).codes\n",
    "    # one hot encoding the Equipment feature\n",
    "    data = pd.concat([data, pd.get_dummies(data.Equipment)], axis=1)\n",
    "    data.drop(['Equipment'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in the column apparent_power are 780813 \n",
      "The number of missing values in the column generator_speed are 437865 \n",
      "The number of missing values in the column nacelle_view are 780813 \n",
      "The number of missing values in the column Digital _1 are 780813 \n",
      "The number of missing values in the column Digital_2 are 780813 \n",
      "The number of missing values in the column Three_phase_current_controller_Setpoint are 780813 \n",
      "The number of missing values in the column wind_direction_deviation are 780813 \n",
      "The number of missing values in the column Average_power_5_sec are 780813 \n",
      "The number of missing values in the column Average_power_30_sec are 780813 \n",
      "The number of missing values in the column switched_on_reactive_power are 780813 \n",
      "The number of missing values in the column performance_class are 780813 \n",
      "The number of missing values in the column Condition_Sheet are 780813 \n",
      "The number of missing values in the column No_comp_levels are 780813 \n",
      "Time_difference is eliminated\n",
      "fast_rateplay is eliminated\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_valid_float(data, status_data):\n",
    "    \"\"\" splitting the data into valid, invalid datasets and \n",
    "    then mapping the valid dataset with the status text\"\"\"\n",
    "    # getting the true values of systemstatus\n",
    "    common_status = np.intersect1d(status_data['Status_Number'], data['system_status'])\n",
    "    # getting the valid data\n",
    "    data_valid = data[data.system_status.isin(common_status)]\n",
    "    data_float = data[~data.system_status.isin(common_status)]\n",
    "    # converting the required data from the status_data into a dictionary    \n",
    "    return data_valid, data_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = splitting_valid_float(data, status_data)\n",
    "data_valid = data_split[0]\n",
    "data_float = data_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_valid(data_valid):\n",
    "    # obtaining the fraction of the data\n",
    "    data_sample= data_valid.sample(frac=0.1).reset_index(drop=True)\n",
    "    target_sample = data_sample['system_status']\n",
    "    #####an error here###################\n",
    "    data_sample.drop(['system_status'], axis=1, inplace=True)\n",
    "    system_stats = pd.factorize(target_sample)\n",
    "    target_sample = system_stats[0]\n",
    "    train_x, val_x, train_y, val_y = train_test_split(\n",
    "            data_sample, target_sample, test_size=0.33, random_state=42)\n",
    "    return train_x, val_x, train_y, val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = split_data_valid(data)\n",
    "train_x, val_x, train_y, val_y = split_data[0], split_data[1], split_data[2], split_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data_float(data_float):\n",
    "    target_float = data_float['system_status']\n",
    "    data_float.drop(['system_status'], axis=1, inplace=True)    \n",
    "    return data_float, target_float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "float_data = processing_data_float(data_float)\n",
    "data_float = float_data[0]\n",
    "target_float = float_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forrest(train_x, val_x, train_y, val_y , data_float, target_float):\n",
    "    \"\"\"applying the random forest for the set of data\"\"\"    \n",
    "    classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    classifier_rf.fit(train_x, train_y)\n",
    "    pred_y_rf = classifier_rf.predict(val_x)\n",
    "    acc_rf_valid = accuracy_score(val_y, pred_y_rf)\n",
    "    print('The accuracy of the random forest with the valid dataset is: {}'.format(acc_rf_valid))\n",
    "    pred_float_rf = classifier_rf.predict(data_float)\n",
    "    return pred_float_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the random forest with the valid dataset is: 0.9078487695054732\n"
     ]
    }
   ],
   "source": [
    "rf = random_forrest(train_x, val_x, train_y, val_y, data_float, target_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pred_float.txt', 'w')\n",
    "for i in rf:\n",
    "    file.write(str(i)+'\\n')\n",
    "file.close()\n",
    "file = open('target_float.txt', 'w')\n",
    "for i in target_float:\n",
    "    file.write(str(i)+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "status = pd.DataFrame()\n",
    "status[\"Status_number\"] = status_data.Status_Number\n",
    "status[\"status_text\"] = status_data.status_text\n",
    "status.dropna(axis=0, inplace=True)    \n",
    "status_text = status.set_index(\"Status_number\").T.to_dict('list')\n",
    "# getting the details of the system status\n",
    "data_valid['system_status'] = data_valid['system_status'].map(status_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_data_test(data):\n",
    "    # obtaining the fraction of the data\n",
    "    data_sample= data.sample(frac=0.1).reset_index(drop=True)\n",
    "    print('The shape of data_sample is {}'.format(data_sample.shape))\n",
    "    target_sample = data_sample['system_status']\n",
    "    print('The shape of target_sample is {}'.format(target_sample.shape))\n",
    "    data_sample.drop(['system_status'], axis=1, inplace=True)\n",
    "    target_sample = target_sample.astype('str')\n",
    "    train_x, val_x, train_y, val_y = train_test_split(\n",
    "            data_sample, target_sample, test_size=0.30, random_state=42)\n",
    "    classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    classifier_rf.fit(train_x, train_y)\n",
    "    pred_y_rf = classifier_rf.predict(val_x)\n",
    "    feat_importances = pd.Series(classifier_rf.feature_importances_, index=val_x.columns)\n",
    "    feat_importances.nlargest(20).plot(kind='barh')\n",
    "    return pred_y_rf, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data_sample is (78064, 53)\n",
      "The shape of target_sample is (78064,)\n"
     ]
    }
   ],
   "source": [
    "pred = whole_data_test(data)\n",
    "pred_stats = pred[0]\n",
    "target_sample = pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pred_float_data.txt', 'w')\n",
    "for i in rf:\n",
    "    file.write(str(i)+'\\n')\n",
    "file.close()\n",
    "file = open('target_sample.txt', 'w')\n",
    "for i in target_sample:\n",
    "    file.write(str(i)+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9061912894961571\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "if pred_stats.shape[0] == target_sample.shape[0]:\n",
    "    acc = accuracy_score(pred_stats, target_sample)\n",
    "    print(acc)\n",
    "else:\n",
    "    print(\"not equal :(\")\n",
    "\n",
    "print(len(set(target_sample))-len(set(pred_stats)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
